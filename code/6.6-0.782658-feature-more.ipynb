{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "uid_train = pd.read_csv('../data/uid_train.txt',sep='\\t',header=None,names=('uid','label'))\n",
    "voice_train = pd.read_csv('../data/voice_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_train = pd.read_csv('../data/sms_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_train = pd.read_csv('../data/wa_train.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_test = pd.read_csv('../data/voice_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_test = pd.read_csv('../data/sms_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_test = pd.read_csv('../data/wa_test_b.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = np.array(['u'])\n",
    "uid_num = np.arange(7000,10000)\n",
    "uid_num_char = uid_num.astype('U')\n",
    "uid_num_str = np.core.defchararray.add(prefix, uid_num_char)\n",
    "uid_test = pd.DataFrame(uid_num_str, columns=['uid'])\n",
    "uid_test.to_csv('../data/uid_test_a.txt',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = pd.concat([voice_train,voice_test],axis=0)\n",
    "sms = pd.concat([sms_train,sms_test],axis=0)\n",
    "wa = pd.concat([wa_train,wa_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice.start_time = voice.start_time.astype(int)\n",
    "voice.end_time = voice.end_time.astype(int)\n",
    "voice['date'] = voice.start_time//1000000\n",
    "voice['hour'] = voice.start_time%1000000//10000\n",
    "\n",
    "sms.start_time = sms.start_time.astype(int)\n",
    "sms['date'] = sms.start_time//1000000\n",
    "sms['hour'] = sms.start_time%1000000//10000\n",
    "\n",
    "wa.date = wa.date.fillna(0).astype(int)\n",
    "wa.up_flow = wa.up_flow.fillna(0).astype(int)\n",
    "wa.down_flow = wa.down_flow.fillna(0).astype(int)\n",
    "wa.visit_dura = wa.visit_dura.fillna(0).astype(int)\n",
    "wa.visit_cnt = wa.visit_cnt.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通话记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "voice['voice_dura']=abs(voice.end_time.astype('int')-voice.start_time.astype('int'))\n",
    "# 不同的电话号码数/电话总数\n",
    "voice_opp_num = voice.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('voice_opp_num_').reset_index()\n",
    "\n",
    "# 不同的电话号码头三位的数量\n",
    "voice_opp_head=voice.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('voice_opp_head_').reset_index()\n",
    "\n",
    "# 每种电话长度的通话次数\n",
    "voice_opp_len=voice.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('voice_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "# 每种类型通话的次数\n",
    "voice_call_type = voice.groupby(['uid','call_type'])['uid'].count().unstack().add_prefix('voice_call_type_').reset_index().fillna(0)\n",
    "\n",
    "# 每种类型通话的平均时长\n",
    "voice_dura_type = voice.groupby(['uid','call_type'])['voice_dura'].mean().unstack().add_prefix('voice_dura_type_').reset_index().fillna(0)\n",
    "\n",
    "# 接入/打出的电话总数\n",
    "voice_in_out = voice.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('voice_in_out_').reset_index().fillna(0)\n",
    "\n",
    "# 通话时长的各统计量\n",
    "voice_dura = voice.groupby(['uid'])['voice_dura'].agg(['std','max','min','median','mean','sum']).add_prefix('voice_dura_').reset_index().fillna(0)\n",
    "\n",
    "## 每个用户收/发电话的号码的不同号码数\n",
    "voice_opp_len_inout = voice.groupby(['uid','in_out'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).unstack().add_prefix('voice_opp_inout_num_').reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "voice_day_count = voice.groupby(['uid'])['date'].agg({'voice_day_count': lambda x: len(pd.unique(x))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天in/out电话量\n",
    "voice_everyday_in_count = voice[voice.in_out==1].groupby(['uid','date'])['uid'].count().unstack().add_prefix('voice_everyday_in_count').reset_index().fillna(0)\n",
    "voice_everyday_out_count = voice[voice.in_out==0].groupby(['uid','date'])['uid'].count().unstack().add_prefix('voice_everyday_out_count').reset_index().fillna(0)\n",
    "\n",
    "voice_everyday_in_dura = voice[voice.in_out==1].groupby(['uid','date'])['voice_dura'].sum().unstack().add_prefix('voice_everyday_in_dura').reset_index().fillna(0)\n",
    "voice_everyday_out_dura = voice[voice.in_out==0].groupby(['uid','date'])['voice_dura'].sum().unstack().add_prefix('voice_everyday_out_dura').reset_index().fillna(0)\n",
    "\n",
    "# 每个小时段的平均电话量\n",
    "voice_hour_count1 = voice[voice.in_out==1].groupby(['uid','hour'])['uid'].count().unstack().add_prefix('voice_hour_count_in').reset_index().fillna(0)\n",
    "voice_hour_count0 = voice[voice.in_out==0].groupby(['uid','hour'])['uid'].count().unstack().add_prefix('voice_hour_count_out').reset_index().fillna(0)\n",
    "voice_hour_count = pd.merge(voice_hour_count1,voice_hour_count0,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每天每种类型的电话数量\n",
    "voice_everyday_call_type_out = voice[voice.in_out==0].groupby(['uid','date','call_type'])['uid'].count().unstack().add_prefix('voice_everyday_call_type_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_1 = voice_everyday_call_type_out.groupby(['uid','date'])['voice_everyday_call_type_1'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_2 = voice_everyday_call_type_out.groupby(['uid','date'])['voice_everyday_call_type_2'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_3 = voice_everyday_call_type_out.groupby(['uid','date'])['voice_everyday_call_type_3'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_4 = voice_everyday_call_type_out.groupby(['uid','date'])['voice_everyday_call_type_4'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_5 = voice_everyday_call_type_out.groupby(['uid','date'])['voice_everyday_call_type_5'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_out = pd.merge(voice_everyday_call_type_1,voice_everyday_call_type_2,how='left',on='uid')\n",
    "voice_everyday_call_type_out = pd.merge(voice_everyday_call_type_out,voice_everyday_call_type_3,how='left',on='uid')\n",
    "voice_everyday_call_type_out = pd.merge(voice_everyday_call_type_out,voice_everyday_call_type_4,how='left',on='uid')\n",
    "voice_everyday_call_type_out = pd.merge(voice_everyday_call_type_out,voice_everyday_call_type_5,how='left',on='uid')\n",
    "\n",
    "voice_everyday_call_type_in = voice[voice.in_out==1].groupby(['uid','date','call_type'])['uid'].count().unstack().add_prefix('voice_everyday_call_type_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_1 = voice_everyday_call_type_in.groupby(['uid','date'])['voice_everyday_call_type_1'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_2 = voice_everyday_call_type_in.groupby(['uid','date'])['voice_everyday_call_type_2'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_3 = voice_everyday_call_type_in.groupby(['uid','date'])['voice_everyday_call_type_3'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "#voice_everyday_call_type_4 = voice_everyday_call_type_in.groupby(['uid','date'])['voice_everyday_call_type_4'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_5 = voice_everyday_call_type_in.groupby(['uid','date'])['voice_everyday_call_type_5'].sum().unstack().add_prefix('day_').reset_index().fillna(0)\n",
    "voice_everyday_call_type_in = pd.merge(voice_everyday_call_type_1,voice_everyday_call_type_2,how='left',on='uid')\n",
    "voice_everyday_call_type_in = pd.merge(voice_everyday_call_type_in,voice_everyday_call_type_3,how='left',on='uid')\n",
    "#voice_everyday_call_type_in = pd.merge(voice_everyday_call_type_in,voice_everyday_call_type_4,how='left',on='uid')\n",
    "voice_everyday_call_type_in = pd.merge(voice_everyday_call_type_in,voice_everyday_call_type_5,how='left',on='uid')\n",
    "\n",
    "voice_everyday_call_type = pd.merge(voice_everyday_call_type_out,voice_everyday_call_type_in,how='left',on='uid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2530: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  import sys\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 每天in/out不同的电话号码数/电话总数\n",
    "voice_everyday_opp_num1 = voice[voice.in_out==1].groupby(['uid','date'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).unstack().add_prefix('voice_in_opp_num_day').reset_index().fillna(0)\n",
    "voice_everyday_opp_num0 = voice[voice.in_out==0].groupby(['uid','date'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).unstack().add_prefix('voice_out_opp_num_day').reset_index().fillna(0)\n",
    "voice_everyday_opp_num = pd.merge(voice_everyday_opp_num1,voice_everyday_opp_num0,how='left',on='uid')\n",
    "\n",
    "# 每天in/out不同的头三位数\n",
    "#voice_everyday_opp_head1 = voice[voice.in_out==1].groupby(['uid','date'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).unstack().add_prefix('voice_everyday_in_opp_head').reset_index().fillna(0)\n",
    "#voice_everyday_opp_head0 = voice[voice.in_out==0].groupby(['uid','date'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).unstack().add_prefix('voice_everyday_out_opp_head').reset_index().fillna(0)\n",
    "#voice_everyday_opp_head = pd.merge(voice_everyday_opp_num1,voice_everyday_opp_num0,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 短信记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# 不同的in/out短信号码数/电话总数\n",
    "sms_out_opp_num = sms[sms.in_out==0].groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('sms_out_opp_num').reset_index()\n",
    "sms_in_opp_num = sms[sms.in_out==1].groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('sms_in_opp_num').reset_index()\n",
    "\n",
    "# in/out号码不同头三位的数量\n",
    "sms_opp_head=sms.groupby(['uid','in_out'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).unstack().add_prefix('sms_opp_head_').reset_index()\n",
    "\n",
    "# 每种号码长度的短信次数\n",
    "sms_out_opp_len=sms[sms.in_out==0].groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('sms_out_opp_len').reset_index().fillna(0)\n",
    "sms_in_opp_len=sms[sms.in_out==1].groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('sms_in_opp_len').reset_index().fillna(0)\n",
    "\n",
    "# 接受/发出短信总数\n",
    "sms_in_out = sms.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('sms_in_out_').reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "sms_day_count = sms.groupby(['uid'])['start_time'].agg({'sms_day_count': lambda x: len(pd.unique(x//1000000))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天in/out短信量\n",
    "sms_everyday_out_count = sms[sms.in_out==0].groupby(['uid','date'])['uid'].count().unstack().add_prefix('sms_everyday_out_count').reset_index().fillna(0)\n",
    "sms_everyday_in_count = sms[sms.in_out==1].groupby(['uid','date'])['uid'].count().unstack().add_prefix('sms_everyday_in_count').reset_index().fillna(0)\n",
    "\n",
    "# 每个小时段的平均in/out短信量\n",
    "sms_hour_out_count = sms[sms.in_out==0].groupby(['uid','hour'])['uid'].count().unstack().add_prefix('sms_hour_out_count').reset_index().fillna(0)\n",
    "sms_hour_in_count = sms[sms.in_out==1].groupby(['uid','hour'])['uid'].count().unstack().add_prefix('sms_hour_in_count').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网站/APP记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# 不同wa数量/wa总数\n",
    "w_a_name_cnt = wa.groupby(['uid','wa_type'])['wa_name'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('w_name_').unstack().reset_index()\n",
    "\n",
    "# 访问wa次数的各统计量\n",
    "w_a_visit_cnt = wa.groupby(['uid','wa_type'])['visit_cnt'].agg(['std','max','min','median','mean','sum']).add_prefix('w_a_visit_cnt').unstack().reset_index().fillna(0)\n",
    "\n",
    "# 访问w/a时长的各统计量\n",
    "w_a_visit_dura = wa.groupby(['uid','wa_type'])['visit_dura'].agg(['std','max','min','median','mean','sum']).add_prefix('w_a_visit_dura').unstack().reset_index().fillna(0)\n",
    "\n",
    "## 每个用户w/a的上/下的流量\n",
    "w_a_upflow = wa.groupby(['uid','wa_type'])['up_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('w_a_upflow_').unstack().reset_index().fillna(0)\n",
    "w_a_downflow = wa.groupby(['uid','wa_type'])['down_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('w_a_downflow_').unstack().reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "wa_day_count = wa.groupby(['uid'])['date'].agg({'wa_day_count': lambda x: len(pd.unique(x))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天web上传流量\n",
    "wa_everyday_web_up_flow = wa[wa.wa_type==0].groupby(['uid','date'])['up_flow'].sum().unstack().add_prefix('wa_everyday_web_up_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天app上传流量\n",
    "wa_everyday_app_up_flow = wa[wa.wa_type==1].groupby(['uid','date'])['up_flow'].sum().unstack().add_prefix('wa_everyday_app_up_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天web下载流量\n",
    "wa_everyday_web_down_flow = wa[wa.wa_type==0].groupby(['uid','date'])['down_flow'].sum().unstack().add_prefix('wa_everyday_web_down_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天app下载流量\n",
    "wa_everyday_app_down_flow = wa[wa.wa_type==1].groupby(['uid','date'])['down_flow'].sum().unstack().add_prefix('wa_everyday_app_down_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天web访问时长\n",
    "wa_everyday_web_visit_dura = wa[wa.wa_type==0].groupby(['uid','date'])['visit_dura'].sum().unstack().add_prefix('wa_everyday_web_visit_dura').reset_index().fillna(0)\n",
    "\n",
    "# 每天app访问时长\n",
    "wa_everyday_app_visit_dura = wa[wa.wa_type==1].groupby(['uid','date'])['visit_dura'].sum().unstack().add_prefix('wa_everyday_app_visit_dura').reset_index().fillna(0)\n",
    "\n",
    "# 每天web访问时长\n",
    "wa_everyday_web_visit_cnt = wa[wa.wa_type==0].groupby(['uid','date'])['visit_cnt'].sum().unstack().add_prefix('wa_everyday_web_visit_cnt').reset_index().fillna(0)\n",
    "\n",
    "# 每天app访问时长\n",
    "wa_everyday_app_visit_cnt = wa[wa.wa_type==1].groupby(['uid','date'])['visit_cnt'].sum().unstack().add_prefix('wa_everyday_app_visit_cnt').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传流量最多的w名字\n",
    "wa_w = wa[wa.wa_type==0]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['up_flow'].sum().unstack().add_prefix('up').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_up_webname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_up_webname['wa_most_up_webname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传流量最多的a名字\n",
    "wa_w = wa[wa.wa_type==1]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['up_flow'].sum().unstack().add_prefix('up').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_up_appname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_up_appname['wa_most_up_appname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载流量最多的w名字\n",
    "wa_w = wa[wa.wa_type==0]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['down_flow'].sum().unstack().add_prefix('down').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_down_webname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_down_webname['wa_most_down_webname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载流量最多的a名字\n",
    "wa_w = wa[wa.wa_type==1]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['down_flow'].sum().unstack().add_prefix('down').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_down_appname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_down_appname['wa_most_down_appname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问次数最多的w名字\n",
    "wa_w = wa[wa.wa_type==0]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['visit_cnt'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_cnt_webname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_cnt_webname['wa_most_cnt_webname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问次数最多的a名字\n",
    "wa_w = wa[wa.wa_type==1]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['visit_cnt'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_cnt_appname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_cnt_appname['wa_most_cnt_appname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问时长最多的w名字\n",
    "wa_w = wa[wa.wa_type==0]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['visit_dura'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_dura_webname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_dura_webname['wa_most_dura_webname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问时长最多的a名字\n",
    "wa_w = wa[wa.wa_type==1]\n",
    "wa_name = wa_w.groupby(['uid','wa_name'])['visit_dura'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_dura_appname = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_dura_appname['wa_most_dura_appname'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 将各个特征拼在一起\n",
    "feature = [voice_opp_num,voice_opp_head,voice_opp_len,voice_call_type,voice_in_out,voice_dura,\n",
    "           voice_opp_len_inout,voice_dura_type,voice_day_count,voice_everyday_out_count,voice_everyday_in_count,\n",
    "           voice_hour_count,voice_everyday_in_dura,voice_everyday_out_dura,voice_everyday_call_type,voice_everyday_opp_num,\n",
    "           voice_everyday_opp_head,\n",
    "           sms_out_opp_num,sms_in_opp_num,sms_opp_head,sms_out_opp_len,sms_in_opp_len,sms_in_out,\n",
    "           sms_day_count,sms_everyday_out_count,sms_everyday_in_count,sms_hour_out_count,sms_hour_in_count,\n",
    "           w_a_name_cnt,w_a_visit_cnt,w_a_visit_dura,w_a_upflow,w_a_downflow,\n",
    "           wa_day_count,wa_everyday_web_up_flow,wa_everyday_web_visit_cnt,wa_everyday_app_visit_cnt,\n",
    "           wa_everyday_app_up_flow,wa_everyday_web_down_flow,wa_everyday_app_down_flow,\n",
    "           wa_everyday_web_visit_dura,wa_everyday_app_visit_dura,wa_most_up_webname,wa_most_down_webname,\n",
    "           wa_most_cnt_webname,wa_most_dura_webname,wa_most_up_appname,wa_most_down_appname,wa_most_cnt_appname,\n",
    "           wa_most_dura_appname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:558: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2530: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# 将train特征和test特征分离\n",
    "train_feature = uid_train\n",
    "for feat in feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:558: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:2530: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "test_feature = uid_test\n",
    "for feat in feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补Nan\n",
    "train_feature = train_feature.drop(['uid_x'],axis=1)\n",
    "train_feature = train_feature.fillna(0)\n",
    "test_feature = test_feature.drop(['uid_x'],axis=1)\n",
    "test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存特征值\n",
    "train_feature.to_csv('../data/train_featureV1.csv',index=None)\n",
    "test_feature.to_csv('../data/test_featureV1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>voice_opp_num_unique_count</th>\n",
       "      <th>voice_opp_num_count</th>\n",
       "      <th>voice_opp_head_unique_count</th>\n",
       "      <th>voice_opp_len_3</th>\n",
       "      <th>voice_opp_len_5</th>\n",
       "      <th>voice_opp_len_6</th>\n",
       "      <th>voice_opp_len_7</th>\n",
       "      <th>voice_opp_len_8</th>\n",
       "      <th>voice_opp_len_9</th>\n",
       "      <th>...</th>\n",
       "      <th>wa_everyday_app_visit_dura44</th>\n",
       "      <th>wa_everyday_app_visit_dura45</th>\n",
       "      <th>wa_most_up_webname</th>\n",
       "      <th>wa_most_down_webname</th>\n",
       "      <th>wa_most_cnt_webname</th>\n",
       "      <th>wa_most_dura_webname</th>\n",
       "      <th>wa_most_up_appname</th>\n",
       "      <th>wa_most_down_appname</th>\n",
       "      <th>wa_most_cnt_appname</th>\n",
       "      <th>wa_most_dura_appname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u7000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2217182.0</td>\n",
       "      <td>977763.0</td>\n",
       "      <td>2814</td>\n",
       "      <td>12710</td>\n",
       "      <td>1097</td>\n",
       "      <td>2813</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u7001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45430.0</td>\n",
       "      <td>149707.0</td>\n",
       "      <td>2813</td>\n",
       "      <td>2813</td>\n",
       "      <td>1097</td>\n",
       "      <td>2813</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u7002</td>\n",
       "      <td>16.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8933.0</td>\n",
       "      <td>7108.0</td>\n",
       "      <td>9420</td>\n",
       "      <td>2813</td>\n",
       "      <td>11993</td>\n",
       "      <td>2813</td>\n",
       "      <td>752</td>\n",
       "      <td>396</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u7003</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>59461.0</td>\n",
       "      <td>9420</td>\n",
       "      <td>2813</td>\n",
       "      <td>12468</td>\n",
       "      <td>12468</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u7004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2744</td>\n",
       "      <td>2744</td>\n",
       "      <td>2743</td>\n",
       "      <td>2744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  voice_opp_num_unique_count  voice_opp_num_count  \\\n",
       "0  u7000                         4.0                  4.0   \n",
       "1  u7001                         2.0                  3.0   \n",
       "2  u7002                        16.0                 65.0   \n",
       "3  u7003                        22.0                 90.0   \n",
       "4  u7004                         7.0                 28.0   \n",
       "\n",
       "   voice_opp_head_unique_count  voice_opp_len_3  voice_opp_len_5  \\\n",
       "0                          4.0              0.0              1.0   \n",
       "1                          2.0              0.0              2.0   \n",
       "2                          9.0              0.0              0.0   \n",
       "3                         16.0              0.0              1.0   \n",
       "4                          6.0              0.0              1.0   \n",
       "\n",
       "   voice_opp_len_6  voice_opp_len_7  voice_opp_len_8  voice_opp_len_9  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              1.0              0.0   \n",
       "3              0.0              3.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "           ...           wa_everyday_app_visit_dura44  \\\n",
       "0          ...                              2217182.0   \n",
       "1          ...                                45430.0   \n",
       "2          ...                                 8933.0   \n",
       "3          ...                                 1675.0   \n",
       "4          ...                                    0.0   \n",
       "\n",
       "   wa_everyday_app_visit_dura45  wa_most_up_webname  wa_most_down_webname  \\\n",
       "0                      977763.0                2814                 12710   \n",
       "1                      149707.0                2813                  2813   \n",
       "2                        7108.0                9420                  2813   \n",
       "3                       59461.0                9420                  2813   \n",
       "4                           0.0                2744                  2744   \n",
       "\n",
       "   wa_most_cnt_webname  wa_most_dura_webname  wa_most_up_appname  \\\n",
       "0                 1097                  2813                 752   \n",
       "1                 1097                  2813                 752   \n",
       "2                11993                  2813                 752   \n",
       "3                12468                 12468                 752   \n",
       "4                 2743                  2744                   0   \n",
       "\n",
       "   wa_most_down_appname  wa_most_cnt_appname  wa_most_dura_appname  \n",
       "0                   752                  752                   752  \n",
       "1                   752                  752                   752  \n",
       "2                   396                  752                   752  \n",
       "3                   752                  752                   752  \n",
       "4                     0                    0                     0  \n",
       "\n",
       "[5 rows x 1661 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
