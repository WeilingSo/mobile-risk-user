{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "uid_train = pd.read_csv('../data/uid_train.txt',sep='\\t',header=None,names=('uid','label'))\n",
    "voice_train = pd.read_csv('../data/voice_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_train = pd.read_csv('../data/sms_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_train = pd.read_csv('../data/wa_train.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_test = pd.read_csv('../data/voice_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_test = pd.read_csv('../data/sms_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_test = pd.read_csv('../data/wa_test_b.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = np.array(['u'])\n",
    "uid_num = np.arange(7000,10000)\n",
    "uid_num_char = uid_num.astype('U')\n",
    "uid_num_str = np.core.defchararray.add(prefix, uid_num_char)\n",
    "uid_test = pd.DataFrame(uid_num_str, columns=['uid'])\n",
    "uid_test.to_csv('../data/uid_test_a.txt',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = pd.concat([voice_train,voice_test],axis=0)\n",
    "sms = pd.concat([sms_train,sms_test],axis=0)\n",
    "wa = pd.concat([wa_train,wa_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice.start_time = voice.start_time.astype(int)\n",
    "voice.end_time = voice.end_time.astype(int)\n",
    "voice['date'] = voice.start_time//1000000\n",
    "voice['hour'] = voice.start_time%1000000//10000\n",
    "\n",
    "sms.start_time = sms.start_time.astype(int)\n",
    "sms['date'] = sms.start_time//1000000\n",
    "sms['hour'] = sms.start_time%1000000//10000\n",
    "\n",
    "wa.date = wa.date.fillna(0).astype(int)\n",
    "wa.up_flow = wa.up_flow.fillna(0).astype(int)\n",
    "wa.down_flow = wa.down_flow.fillna(0).astype(int)\n",
    "wa.visit_dura = wa.visit_dura.fillna(0).astype(int)\n",
    "wa.visit_cnt = wa.visit_cnt.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通话记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-54bbfa0db210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# 每个小时段的平均电话量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mvoice_hour_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'voice_hour_count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_groupby_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'numeric_only'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No numeric types to aggregate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "voice['voice_dura']=abs(voice.end_time.astype('int')-voice.start_time.astype('int'))\n",
    "# 不同的电话号码数/电话总数\n",
    "voice_opp_num = voice.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('voice_opp_num_').reset_index()\n",
    "\n",
    "# 不同的电话号码头三位的数量\n",
    "voice_opp_head=voice.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('voice_opp_head_').reset_index()\n",
    "\n",
    "# 每种电话长度的通话次数\n",
    "voice_opp_len=voice.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('voice_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "# 每种类型通话的次数\n",
    "voice_call_type = voice.groupby(['uid','call_type'])['uid'].count().unstack().add_prefix('voice_call_type_').reset_index().fillna(0)\n",
    "\n",
    "# 每种类型通话的平均时长\n",
    "voice_dura_type = voice.groupby(['uid','call_type'])['voice_dura'].mean().unstack().add_prefix('voice_dura_type_').reset_index().fillna(0)\n",
    "\n",
    "# 接入/打出的电话总数\n",
    "voice_in_out = voice.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('voice_in_out_').reset_index().fillna(0)\n",
    "\n",
    "# 通话时长的各统计量\n",
    "voice_dura = voice.groupby(['uid'])['voice_dura'].agg(['std','max','min','median','mean','sum']).add_prefix('voice_dura_').reset_index().fillna(0)\n",
    "\n",
    "## 每个用户收/发电话的号码的不同号码数\n",
    "voice_opp_len_inout = voice.groupby(['uid','in_out'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).unstack().add_prefix('voice_opp_inout_num_').reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "voice_day_count = voice.groupby(['uid'])['start_time'].agg({'voice_day_count': lambda x: len(pd.unique(x//1000000))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天电话量\n",
    "voice_everyday_count = voice.groupby(['uid','date'])['uid'].count().unstack().add_prefix('voice_everyday_count').reset_index().fillna(0)\n",
    "\n",
    "# 每个小时段的平均电话量\n",
    "voice_hour_count = voice.groupby(['uid','hour'])['uid'].mean().unstack().add_prefix('voice_hour_count').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 短信记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同的短信号码数/电话总数\n",
    "sms_opp_num = sms.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('sms_opp_num_').reset_index()\n",
    "\n",
    "# 号码不同头三位的数量\n",
    "sms_opp_head=sms.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('sms_opp_head_').reset_index()\n",
    "\n",
    "# 每种号码长度的通话次数\n",
    "sms_opp_len=sms.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('sms_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "# 接受/发出短信总数\n",
    "sms_in_out = sms.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('sms_in_out_').reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "sms_day_count = sms.groupby(['uid'])['start_time'].agg({'sms_day_count': lambda x: len(pd.unique(x//1000000))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天短信量\n",
    "sms_everyday_count = sms.groupby(['uid','date'])['uid'].count().unstack().add_prefix('sms_everyday_count').reset_index().fillna(0)\n",
    "\n",
    "# 每个小时段的平均短信量\n",
    "sms_hour_count = sms.groupby(['uid','hour'])['uid'].mean().unstack().add_prefix('sms_hour_count').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网站/APP记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同wa数量/wa总数\n",
    "wa_name_cnt = wa.groupby(['uid'])['wa_name'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('wa_name_').reset_index()\n",
    "\n",
    "# 访问wa次数的各统计量\n",
    "visit_cnt = wa.groupby(['uid'])['visit_cnt'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_visit_cnt_').reset_index()\n",
    "\n",
    "# 访问wa时长的各统计量\n",
    "visit_dura = wa.groupby(['uid'])['visit_dura'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_visit_dura_').reset_index()\n",
    "\n",
    "# 上传流量的各统计量\n",
    "up_flow = wa.groupby(['uid'])['up_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_up_flow_').reset_index()\n",
    "\n",
    "# 下载流量的各统计量\n",
    "down_flow = wa.groupby(['uid'])['down_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_down_flow_').reset_index()\n",
    "\n",
    "## 每个用户上/下的流量\n",
    "w_a_upflow = wa.groupby(['uid','wa_type'])['up_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('w_a_upflow_').unstack().reset_index().fillna(0)\n",
    "\n",
    "# 不同的日期数\n",
    "wa_day_count = wa.groupby(['uid'])['date'].agg({'wa_day_count': lambda x: len(pd.unique(x))}).reset_index().fillna(0)\n",
    "\n",
    "# 每天上传流量\n",
    "wa_everyday_up_flow = wa.groupby(['uid','date'])['up_flow'].sum().unstack().add_prefix('wa_everyday_up_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天下载流量\n",
    "wa_everyday_down_flow = wa.groupby(['uid','date'])['down_flow'].sum().unstack().add_prefix('wa_everyday_down_flow').reset_index().fillna(0)\n",
    "\n",
    "# 每天访问时长\n",
    "wa_everyday_visit_dura = wa.groupby(['uid','date'])['visit_dura'].sum().unstack().add_prefix('wa_everyday_visit_dura').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传流量最多的wa名字\n",
    "wa_name = wa.groupby(['uid','wa_name'])['up_flow'].sum().unstack().add_prefix('up').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_up_name = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_up_name['wa_most_up_name'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载流量最多的wa名字\n",
    "wa_name = wa.groupby(['uid','wa_name'])['down_flow'].sum().unstack().add_prefix('down').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_down_name = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_down_name['wa_most_down_name'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问次数最多的wa名字\n",
    "wa_name = wa.groupby(['uid','wa_name'])['visit_cnt'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_cnt_name = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_cnt_name['wa_most_cnt_name'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问时长最多的wa名字\n",
    "wa_name = wa.groupby(['uid','wa_name'])['visit_dura'].sum().unstack().add_prefix('cnt').reset_index().fillna(0)\n",
    "wa_uid = wa_name.uid;\n",
    "wa_name = wa_name.drop(['uid'],axis=1)\n",
    "col_name = np.arange(0,wa_name.shape[1])\n",
    "col_name = col_name.astype('U')\n",
    "wa_name.columns =col_name\n",
    "wa_name_t = wa_name.T\n",
    "col_name2 = np.arange(0,wa_name_t.shape[1])\n",
    "col_name2 = col_name2.astype('U')\n",
    "wa_name_t.columns =col_name2\n",
    "ss = wa_name_t.idxmax()\n",
    "wa_most_dura_name = pd.DataFrame(wa_uid, columns=['uid'])\n",
    "l = list(ss)\n",
    "wa_most_dura_name['wa_most_cnt_name'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将各个特征拼在一起\n",
    "feature = [voice_opp_num,voice_opp_head,voice_opp_len,voice_call_type,voice_in_out,voice_dura,\n",
    "           voice_opp_len_inout,voice_dura_type,voice_day_count,voice_everyday_count,voice_hour_count,\n",
    "           sms_opp_num,sms_opp_head,sms_opp_len,sms_in_out,sms_day_count,sms_everyday_count,sms_hour_count,\n",
    "           wa_name_cnt,visit_cnt,visit_dura,up_flow,down_flow,w_a_upflow,wa_day_count,wa_everyday_up_flow,\n",
    "           wa_everyday_down_flow,wa_everyday_visit_dura,wa_most_up_name,wa_most_down_name,wa_most_cnt_name,wa_most_dura_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将train特征和test特征分离\n",
    "train_feature = uid_train\n",
    "for feat in feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = uid_test\n",
    "for feat in feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填补Nan\n",
    "train_feature.fillna(0,inplace=True)\n",
    "test_feature.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存特征值\n",
    "train_feature.to_csv('../data/train_featureV1.csv',index=None)\n",
    "test_feature.to_csv('../data/test_featureV1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
