{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本库import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-*- encoding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_featureV1.csv')\n",
    "test = pd.read_csv('./data/test_featureV1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>voice_opp_num_unique_count</th>\n",
       "      <th>voice_opp_num_count</th>\n",
       "      <th>voice_opp_head_unique_count</th>\n",
       "      <th>voice_opp_len_3</th>\n",
       "      <th>voice_opp_len_5</th>\n",
       "      <th>voice_opp_len_6</th>\n",
       "      <th>voice_opp_len_7</th>\n",
       "      <th>voice_opp_len_8</th>\n",
       "      <th>...</th>\n",
       "      <th>('w_a_downflow_max', 0.0)</th>\n",
       "      <th>('w_a_downflow_max', 1.0)</th>\n",
       "      <th>('w_a_downflow_min', 0.0)</th>\n",
       "      <th>('w_a_downflow_min', 1.0)</th>\n",
       "      <th>('w_a_downflow_median', 0.0)</th>\n",
       "      <th>('w_a_downflow_median', 1.0)</th>\n",
       "      <th>('w_a_downflow_mean', 0.0)</th>\n",
       "      <th>('w_a_downflow_mean', 1.0)</th>\n",
       "      <th>('w_a_downflow_sum', 0.0)</th>\n",
       "      <th>('w_a_downflow_sum', 1.0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>u4406</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32884193.0</td>\n",
       "      <td>29869689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8178.0</td>\n",
       "      <td>16136.0</td>\n",
       "      <td>2.278208e+05</td>\n",
       "      <td>7.828379e+05</td>\n",
       "      <td>392762983.0</td>\n",
       "      <td>320963542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>u4332</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>234506317.0</td>\n",
       "      <td>34132.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70350.0</td>\n",
       "      <td>14470.0</td>\n",
       "      <td>2.009716e+07</td>\n",
       "      <td>1.576800e+04</td>\n",
       "      <td>864177816.0</td>\n",
       "      <td>63072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0002</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15438.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.267207e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>94749.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>u0850</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40507314.0</td>\n",
       "      <td>52066905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>6806.0</td>\n",
       "      <td>6.292996e+05</td>\n",
       "      <td>1.217871e+06</td>\n",
       "      <td>200117261.0</td>\n",
       "      <td>109608385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>u1010</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1786.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.786500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3573.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  label  voice_opp_num_unique_count  voice_opp_num_count  \\\n",
       "4405  u4406      1                        48.0                120.0   \n",
       "4331  u4332      1                         1.0                  1.0   \n",
       "1     u0002      0                         2.0                  2.0   \n",
       "849   u0850      0                        25.0                115.0   \n",
       "1009  u1010      0                        28.0                281.0   \n",
       "\n",
       "      voice_opp_head_unique_count  voice_opp_len_3  voice_opp_len_5  \\\n",
       "4405                         39.0              0.0              8.0   \n",
       "4331                          1.0              0.0              1.0   \n",
       "1                             1.0              0.0              0.0   \n",
       "849                          16.0              0.0              1.0   \n",
       "1009                         24.0              0.0              1.0   \n",
       "\n",
       "      voice_opp_len_6  voice_opp_len_7  voice_opp_len_8  \\\n",
       "4405              0.0              0.0              3.0   \n",
       "4331              0.0              0.0              0.0   \n",
       "1                 0.0              0.0              0.0   \n",
       "849               0.0              0.0              0.0   \n",
       "1009              0.0              1.0              0.0   \n",
       "\n",
       "                ...              ('w_a_downflow_max', 0.0)  \\\n",
       "4405            ...                             32884193.0   \n",
       "4331            ...                            234506317.0   \n",
       "1               ...                                15438.0   \n",
       "849             ...                             40507314.0   \n",
       "1009            ...                                 3429.0   \n",
       "\n",
       "      ('w_a_downflow_max', 1.0)  ('w_a_downflow_min', 0.0)  \\\n",
       "4405                 29869689.0                        0.0   \n",
       "4331                    34132.0                       60.0   \n",
       "1                           0.0                        0.0   \n",
       "849                  52066905.0                        0.0   \n",
       "1009                        0.0                      144.0   \n",
       "\n",
       "      ('w_a_downflow_min', 1.0)  ('w_a_downflow_median', 0.0)  \\\n",
       "4405                        0.0                        8178.0   \n",
       "4331                        0.0                       70350.0   \n",
       "1                           0.0                        1656.0   \n",
       "849                        40.0                         856.0   \n",
       "1009                        0.0                        1786.5   \n",
       "\n",
       "      ('w_a_downflow_median', 1.0)  ('w_a_downflow_mean', 0.0)  \\\n",
       "4405                       16136.0                2.278208e+05   \n",
       "4331                       14470.0                2.009716e+07   \n",
       "1                              0.0                3.267207e+03   \n",
       "849                         6806.0                6.292996e+05   \n",
       "1009                           0.0                1.786500e+03   \n",
       "\n",
       "      ('w_a_downflow_mean', 1.0)  ('w_a_downflow_sum', 0.0)  \\\n",
       "4405                7.828379e+05                392762983.0   \n",
       "4331                1.576800e+04                864177816.0   \n",
       "1                   0.000000e+00                    94749.0   \n",
       "849                 1.217871e+06                200117261.0   \n",
       "1009                0.000000e+00                     3573.0   \n",
       "\n",
       "      ('w_a_downflow_sum', 1.0)  \n",
       "4405                320963542.0  \n",
       "4331                    63072.0  \n",
       "1                           0.0  \n",
       "849                 109608385.0  \n",
       "1009                        0.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1)  \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 3 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 300,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "   # 'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':300,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    #'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 300,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 300,\n",
    "    # 'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "   # 'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "\n",
    "#准备训练测试集\n",
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train['label'].ravel()\n",
    "x_train = train.drop(['uid','label'], axis=1).values # Creates an array of the train data\n",
    "x_test = test.drop(['uid'], axis=1).values # Creats an array of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止过拟合 划分训练测试集\n",
    "#def get_oof(clf, x_train, y_train, x_test):\n",
    "#    clf.train(x_train, y_train)\n",
    "#\n",
    "#    oof_train = clf.predict(x_train)\n",
    "#    oof_test = clf.predict(x_test)\n",
    "#    \n",
    "#    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "# 防止过拟合 划分训练测试集\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "#svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.87397995e-02 1.39775049e-02 1.56938296e-02 6.15061265e-04\n",
      " 4.65879554e-03 3.94195511e-04 1.20172072e-03 4.62949777e-03\n",
      " 1.26383853e-03 1.43272018e-03 1.69518908e-02 6.88223949e-02\n",
      " 7.87550510e-04 6.19051878e-04 4.49405154e-03 2.22346477e-05\n",
      " 0.00000000e+00 0.00000000e+00 4.03227799e-05 2.06498013e-05\n",
      " 0.00000000e+00 0.00000000e+00 2.22952695e-02 8.78444410e-03\n",
      " 6.83210127e-03 0.00000000e+00 2.66912939e-04 1.42427675e-02\n",
      " 2.70405853e-02 1.10520615e-02 1.45007808e-02 6.69771161e-03\n",
      " 8.78252391e-03 1.12157058e-02 1.43357089e-02 2.06943265e-02\n",
      " 2.39291626e-02 1.21644123e-02 2.29182032e-02 1.46330989e-02\n",
      " 8.32991154e-03 6.13321227e-03 0.00000000e+00 1.92094273e-04\n",
      " 2.36960449e-02 1.01165038e-02 6.54853708e-03 1.26138571e-04\n",
      " 0.00000000e+00 9.49844952e-06 8.58549454e-04 1.92763146e-04\n",
      " 3.17422503e-03 8.67573659e-03 3.62271050e-02 1.35667409e-03\n",
      " 1.42933579e-02 2.96940341e-03 7.55151021e-02 8.29931051e-04\n",
      " 4.77383909e-04 7.96357784e-05 1.68596133e-04 6.55829901e-05\n",
      " 5.53853306e-05 8.17952788e-05 1.85114692e-02 2.09697432e-02\n",
      " 8.17175635e-03 8.29912646e-03 1.32107996e-02 7.39024699e-03\n",
      " 3.74317747e-05 3.65225171e-03 1.31538735e-02 7.28750608e-03\n",
      " 1.17932395e-02 6.71562488e-03 3.83941298e-04 8.76416125e-03\n",
      " 1.38895347e-02 9.74009099e-03 7.13101491e-03 7.35821684e-03\n",
      " 1.49933650e-03 8.92933840e-03 9.49931804e-03 9.06718252e-03\n",
      " 7.71644142e-03 6.29421786e-03 8.15112056e-04 8.34365479e-03\n",
      " 9.01902522e-03 7.32998412e-03 6.97090337e-03 6.15298205e-03\n",
      " 6.25734501e-03 6.19232205e-03 1.30404253e-03 3.40826801e-03\n",
      " 1.01845895e-02 7.01127652e-03 9.04182466e-03 8.92438941e-03\n",
      " 1.12950128e-02 7.88110278e-03 8.16374637e-03 6.95067492e-03\n",
      " 7.24800122e-03 7.09457659e-03 1.01925607e-03 2.83684229e-03\n",
      " 1.05386666e-02 7.18877413e-03 9.78415022e-03 8.13049899e-03\n",
      " 1.04745217e-02 6.04853666e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.96743543e-03 2.29825320e-02 4.82992007e-02 2.52837855e-03\n",
      " 2.84821000e-03 1.52603287e-03 2.54667128e-03 3.11989832e-03\n",
      " 6.36738723e-03 3.06840895e-03 2.23688038e-02 2.18941707e-02\n",
      " 1.30980253e-03 1.53974829e-03 1.07066259e-02 2.85787278e-04\n",
      " 0.00000000e+00 0.00000000e+00 3.29141749e-04 1.01102026e-04\n",
      " 0.00000000e+00 0.00000000e+00 3.20092876e-02 1.12967391e-02\n",
      " 3.48500488e-03 3.99648280e-05 2.97195878e-04 1.49834091e-02\n",
      " 3.74105409e-02 9.72741864e-03 6.94917594e-03 4.19559543e-03\n",
      " 6.13671568e-03 1.02925590e-02 6.63433088e-03 1.21781164e-02\n",
      " 2.15794303e-02 1.40585585e-02 3.11882948e-02 8.94910116e-03\n",
      " 5.73244626e-03 4.59034188e-03 1.82307050e-05 5.63657103e-04\n",
      " 4.08152419e-02 7.92777206e-03 9.93463830e-03 1.40225567e-04\n",
      " 0.00000000e+00 8.37357768e-04 3.83275779e-03 3.97727835e-04\n",
      " 2.21708475e-03 1.33719495e-02 5.89346857e-02 3.30789982e-03\n",
      " 1.18454411e-02 8.29728178e-03 1.39040199e-02 2.12701215e-03\n",
      " 9.84980069e-04 6.07116921e-04 1.70043946e-04 7.29400763e-04\n",
      " 1.28537539e-04 3.08837686e-04 5.58295806e-02 1.03966399e-02\n",
      " 1.74405759e-02 1.52522629e-02 1.12827786e-02 5.62922612e-03\n",
      " 6.31177608e-04 7.46588704e-03 1.31790609e-02 1.65282478e-02\n",
      " 1.02869534e-02 4.32025028e-03 3.57739777e-04 7.75026194e-03\n",
      " 1.41947710e-02 1.50212619e-02 4.89355526e-03 5.97845555e-03\n",
      " 1.62310115e-03 6.49846606e-03 8.37776460e-03 7.32430486e-03\n",
      " 6.10395123e-03 7.68196968e-03 3.88517955e-04 6.48344503e-03\n",
      " 7.74311046e-03 1.09213807e-02 5.76558366e-03 4.37523668e-03\n",
      " 4.09121586e-03 4.22419935e-03 1.46270388e-03 2.91276801e-03\n",
      " 7.45360204e-03 3.17193190e-03 7.87084562e-03 5.89175389e-03\n",
      " 8.55293402e-03 8.43551639e-03 7.92457693e-03 4.73636091e-03\n",
      " 9.37910847e-03 3.05888266e-03 6.10553255e-04 2.73727970e-03\n",
      " 4.07730387e-03 2.99904259e-03 1.37655410e-02 5.02077095e-03\n",
      " 1.19378699e-02 5.03425460e-03]\n",
      "[0.02666667 0.00666667 0.02666667 0.00333333 0.00666667 0.00666667\n",
      " 0.01       0.02       0.00333333 0.01       0.         0.03\n",
      " 0.00666667 0.         0.01       0.00333333 0.         0.\n",
      " 0.         0.         0.         0.         0.00666667 0.00666667\n",
      " 0.01666667 0.         0.         0.00666667 0.01       0.00666667\n",
      " 0.01333333 0.00666667 0.02       0.01333333 0.02333333 0.01666667\n",
      " 0.01666667 0.00333333 0.00333333 0.01333333 0.01333333 0.01666667\n",
      " 0.         0.         0.01       0.00666667 0.00666667 0.\n",
      " 0.         0.         0.         0.         0.00666667 0.01333333\n",
      " 0.01       0.00333333 0.02       0.01       0.04333333 0.\n",
      " 0.         0.         0.         0.00333333 0.         0.\n",
      " 0.02666667 0.04333333 0.01333333 0.01       0.01666667 0.00666667\n",
      " 0.00333333 0.00333333 0.01333333 0.00666667 0.00666667 0.01\n",
      " 0.         0.00333333 0.01       0.01       0.01333333 0.00333333\n",
      " 0.00333333 0.01       0.01666667 0.00666667 0.02333333 0.00333333\n",
      " 0.00333333 0.01333333 0.00666667 0.         0.01       0.01\n",
      " 0.01       0.01       0.00333333 0.01333333 0.00333333 0.01333333\n",
      " 0.01       0.00333333 0.01333333 0.01333333 0.00333333 0.00333333\n",
      " 0.01       0.00666667 0.00333333 0.00666667 0.00666667 0.00333333\n",
      " 0.01333333 0.00333333 0.00666667 0.01666667]\n"
     ]
    }
   ],
   "source": [
    "# 得出特征重要性评估\n",
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "ada_feature = ada.feature_importances(x_train, y_train)\n",
    "#gb_feature = gb.feature_importances(x_train,y_train)\n",
    "#svc_feature = svc.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二层模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138628</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.121024</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.180036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.345592</td>\n",
       "      <td>0.108006</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>0.240109</td>\n",
       "      <td>0.384256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoost   ExtraTrees  GradientBoost  RandomForest        label\n",
       "count  4999.000000  4999.000000    4999.000000   4999.000000  4999.000000\n",
       "mean      0.138628     0.011802       0.121024      0.061412     0.180036\n",
       "std       0.345592     0.108006       0.326188      0.240109     0.384256\n",
       "min       0.000000     0.000000       0.000000      0.000000     0.000000\n",
       "25%       0.000000     0.000000       0.000000      0.000000     0.000000\n",
       "50%       0.000000     0.000000       0.000000      0.000000     0.000000\n",
       "75%       0.000000     0.000000       0.000000      0.000000     0.000000\n",
       "max       1.000000     1.000000       1.000000      1.000000     1.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {\n",
    "    'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "     'GradientBoost': gb_oof_train.ravel(),\n",
    "     'label':y_train.ravel()\n",
    "    })\n",
    "base_predictions_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": "Viridis",
         "reversescale": true,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest",
          "label"
         ],
         "y": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest",
          "label"
         ],
         "z": [
          [
           1,
           0.25633526320919636,
           0.6409669442776154,
           0.43990049175995677,
           0.4629030560622297
          ],
          [
           0.25633526320919636,
           1,
           0.277482501122854,
           0.3963797541606296,
           0.209122961852602
          ],
          [
           0.6409669442776154,
           0.277482501122854,
           1,
           0.5284129541426759,
           0.4965749509972691
          ],
          [
           0.43990049175995677,
           0.3963797541606296,
           0.5284129541426759,
           1,
           0.5350505767407344
          ],
          [
           0.4629030560622297,
           0.209122961852602,
           0.4965749509972691,
           0.5350505767407344,
           1
          ]
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"2b3ef098-9e2d-448a-9d8d-89ae3446e8d0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2b3ef098-9e2d-448a-9d8d-89ae3446e8d0\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.25633526320919636, 0.6409669442776154, 0.43990049175995677, 0.4629030560622297], [0.25633526320919636, 1.0, 0.277482501122854, 0.3963797541606296, 0.209122961852602], [0.6409669442776154, 0.277482501122854, 1.0, 0.5284129541426759, 0.4965749509972691], [0.43990049175995677, 0.3963797541606296, 0.5284129541426759, 1.0, 0.5350505767407344], [0.4629030560622297, 0.209122961852602, 0.4965749509972691, 0.5350505767407344, 1.0]], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"label\"], \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"label\"], \"colorscale\": \"Viridis\", \"showscale\": true, \"reversescale\": true}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2b3ef098-9e2d-448a-9d8d-89ae3446e8d0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2b3ef098-9e2d-448a-9d8d-89ae3446e8d0\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.25633526320919636, 0.6409669442776154, 0.43990049175995677, 0.4629030560622297], [0.25633526320919636, 1.0, 0.277482501122854, 0.3963797541606296, 0.209122961852602], [0.6409669442776154, 0.277482501122854, 1.0, 0.5284129541426759, 0.4965749509972691], [0.43990049175995677, 0.3963797541606296, 0.5284129541426759, 1.0, 0.5350505767407344], [0.4629030560622297, 0.209122961852602, 0.4965749509972691, 0.5350505767407344, 1.0]], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"label\"], \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"label\"], \"colorscale\": \"Viridis\", \"showscale\": true, \"reversescale\": true}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化第一层模型的相关程度\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= base_predictions_train.astype(float).corr().values ,\n",
    "        x= base_predictions_train.columns.values,\n",
    "        y= base_predictions_train.columns.values,\n",
    "          colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            reversescale = True\n",
    "    )\n",
    "]\n",
    "\n",
    "py.iplot(data, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成第二层模型的训练测试集\n",
    "#x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train,gb_oof_train, svc_oof_train), axis=1)\n",
    "#x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test,gb_oof_test, svc_oof_test), axis=1)\n",
    "x_train = np.concatenate(( et_oof_train, ada_oof_train,rf_oof_train, gb_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, ada_oof_test,rf_oof_test, gb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgboost 第二层分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(x_train,label=y_train)\n",
    "dtest = lgb.Dataset(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "#    'metric': ('multi_logloss', 'multi_error'),\n",
    "    #'metric_freq': 100,\n",
    "    'is_training_metric': False,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'num_leaves': 64,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbosity':-1,\n",
    "    'max_depth':7,\n",
    "#    'gpu_device_id':2,\n",
    "#    'device':'gpu'\n",
    "#    'lambda_l1': 0.001,\n",
    "#    'skip_drop': 0.95,\n",
    "#    'max_drop' : 10\n",
    "    #'lambda_l2': 0.005\n",
    "    #'num_threads': 18\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetric(preds,dtrain):\n",
    "    \n",
    "    label = dtrain.get_label()\n",
    "    \n",
    "    \n",
    "    pre = pd.DataFrame({'preds':preds,'label':label})\n",
    "    pre= pre.sort_values(by='preds',ascending=False)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(pre.label,pre.preds)\n",
    "\n",
    "    pre.preds=pre.preds.map(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "    f1 = metrics.f1_score(pre.label,pre.preds)\n",
    "    \n",
    "    \n",
    "    res = 0.6*auc +0.4*f1\n",
    "    \n",
    "    return 'res',res,True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tcv_agg's res: 0.692042 + 0.00509468\n",
      "[10]\tcv_agg's res: 0.691769 + 0.0050846\n",
      "[15]\tcv_agg's res: 0.692043 + 0.00509344\n",
      "[20]\tcv_agg's res: 0.692046 + 0.00509686\n",
      "[25]\tcv_agg's res: 0.691766 + 0.00507752\n",
      "[30]\tcv_agg's res: 0.692042 + 0.00508982\n",
      "[35]\tcv_agg's res: 0.691783 + 0.00509854\n",
      "[40]\tcv_agg's res: 0.691775 + 0.00508772\n",
      "[45]\tcv_agg's res: 0.691775 + 0.00508772\n",
      "[50]\tcv_agg's res: 0.691788 + 0.00509606\n",
      "[55]\tcv_agg's res: 0.691971 + 0.00508164\n",
      "[60]\tcv_agg's res: 0.691978 + 0.00507694\n",
      "[65]\tcv_agg's res: 0.691987 + 0.00506596\n",
      "[70]\tcv_agg's res: 0.69218 + 0.00486049\n",
      "[75]\tcv_agg's res: 0.697512 + 0.00906216\n",
      "[80]\tcv_agg's res: 0.697518 + 0.00905482\n",
      "[85]\tcv_agg's res: 0.697533 + 0.00903588\n",
      "[90]\tcv_agg's res: 0.697543 + 0.00904813\n",
      "[95]\tcv_agg's res: 0.697543 + 0.00904813\n",
      "[100]\tcv_agg's res: 0.697549 + 0.00905513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'res-mean': [0.677842720970808, 0.7006012348568259],\n",
       " 'res-stdv': [0.0037983771228491774, 0.007885217832597307]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.cv(lgb_params,dtrain,feval=evalMetric,early_stopping_rounds=100,verbose_eval=5,num_boost_round=10000,nfold=3,metrics=['evalMetric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's res: 0.70959\n",
      "[10]\ttraining's res: 0.709606\n",
      "[15]\ttraining's res: 0.70958\n",
      "[20]\ttraining's res: 0.709592\n",
      "[25]\ttraining's res: 0.709592\n",
      "[30]\ttraining's res: 0.709587\n",
      "[35]\ttraining's res: 0.709591\n",
      "[40]\ttraining's res: 0.709592\n",
      "[45]\ttraining's res: 0.709617\n",
      "[50]\ttraining's res: 0.709651\n",
      "[55]\ttraining's res: 0.709649\n",
      "[60]\ttraining's res: 0.709689\n",
      "[65]\ttraining's res: 0.710013\n",
      "[70]\ttraining's res: 0.710029\n",
      "[75]\ttraining's res: 0.710029\n",
      "[80]\ttraining's res: 0.710029\n",
      "[85]\ttraining's res: 0.710029\n",
      "[90]\ttraining's res: 0.710034\n",
      "[95]\ttraining's res: 0.710034\n",
      "[100]\ttraining's res: 0.710062\n",
      "[105]\ttraining's res: 0.710062\n",
      "[110]\ttraining's res: 0.710062\n",
      "[115]\ttraining's res: 0.710062\n",
      "[120]\ttraining's res: 0.710062\n",
      "[125]\ttraining's res: 0.710061\n",
      "[130]\ttraining's res: 0.710061\n",
      "[135]\ttraining's res: 0.710061\n",
      "[140]\ttraining's res: 0.710061\n",
      "[145]\ttraining's res: 0.710061\n",
      "[150]\ttraining's res: 0.710061\n",
      "[155]\ttraining's res: 0.710061\n",
      "[160]\ttraining's res: 0.710061\n",
      "[165]\ttraining's res: 0.710061\n",
      "[170]\ttraining's res: 0.710061\n",
      "[175]\ttraining's res: 0.710061\n",
      "[180]\ttraining's res: 0.710061\n",
      "[185]\ttraining's res: 0.710061\n",
      "[190]\ttraining's res: 0.710061\n",
      "[195]\ttraining's res: 0.710061\n",
      "[200]\ttraining's res: 0.710061\n",
      "[205]\ttraining's res: 0.710061\n",
      "[210]\ttraining's res: 0.710061\n",
      "[215]\ttraining's res: 0.710061\n",
      "[220]\ttraining's res: 0.710061\n",
      "[225]\ttraining's res: 0.710061\n",
      "[230]\ttraining's res: 0.710061\n",
      "[235]\ttraining's res: 0.710061\n",
      "[240]\ttraining's res: 0.710061\n",
      "[245]\ttraining's res: 0.710061\n",
      "[250]\ttraining's res: 0.710061\n",
      "[255]\ttraining's res: 0.710061\n",
      "[260]\ttraining's res: 0.710061\n",
      "[265]\ttraining's res: 0.710061\n",
      "[270]\ttraining's res: 0.710061\n",
      "[275]\ttraining's res: 0.710061\n",
      "[280]\ttraining's res: 0.710061\n",
      "[285]\ttraining's res: 0.710061\n",
      "[290]\ttraining's res: 0.710061\n",
      "[295]\ttraining's res: 0.710061\n",
      "[300]\ttraining's res: 0.710061\n"
     ]
    }
   ],
   "source": [
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08033013, 0.50968402, 0.08033013, ..., 0.08033013, 0.08033013,\n",
       "       0.08033013])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'uid':test.uid,'label':pred})\n",
    "res=res.sort_values(by='label',ascending=False)\n",
    "res.label=res.label.map(lambda x: 1 if x>=0.5 else 0)\n",
    "#res.label = res.label.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('./result/lgb-stack-baseline.csv',index=False,header=False,sep=',',columns=['uid','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
