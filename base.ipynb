{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本库import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-*- encoding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入通话记录，短信记录，访问记录数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入用户通话记录\n",
    "names_voice = ['uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out']\n",
    "voice_data = pd.read_table(\"./data/train/voice_train.txt\",sep='\\t',header=None,encoding='utf-8',names = names_voice,index_col = False,low_memory=False)\n",
    "\n",
    "# 导入用户短信记录\n",
    "names_sms = ['uid','opp_num','opp_head','opp_len','start_time','in_out']\n",
    "sms_data = pd.read_table(\"./data/train/sms_train.txt\",sep='\\t',header=None,encoding='utf-8',names = names_sms,index_col = False,low_memory=False)\n",
    "\n",
    "# 导入用户通话记录\n",
    "names_wa = ['uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date']\n",
    "wa_data = pd.read_table(\"./data/train/wa_train.txt\",sep='\\t',header=None,encoding='utf-8',names = names_wa,index_col = False,low_memory=False)\n",
    "\n",
    "# 读取训练与测试数据\n",
    "uid_label = pd.read_table(\"./data/train/uid_train.txt\",sep='\\t',header=None,names=['uid','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 对用户的电话接拨情况统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVoiceFeature(data):\n",
    "    voice_feature = pd.DataFrame() \n",
    "    ## 每个用户的电话总数量 丢\n",
    "    gp = data.groupby('uid')['in_out']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    voice_feature['uid'] = x.index\n",
    "    #voice_feature['voice_count_all'] = x.values\n",
    "    \n",
    "    ## 每个用户收/发电话的总数\n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_len']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    voice_feature['send_voice_cnt'] = x['0']\n",
    "    voice_feature['recv_voice_cnt'] = x['1']\n",
    "    \n",
    "    \n",
    "    ## 每个用户收/发电话的号码的平均长度\n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_len']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    voice_feature['send_voice_opplen_mean'] = x['0']\n",
    "    voice_feature['recv_voice_opplen_mean'] = x['1']\n",
    "    \n",
    "    ## 每个用户通话的平均时长和最长时长 丢\n",
    "    data['dura']=abs(data.end_time-data.start_time)\n",
    "\n",
    "    gp = data.groupby('uid')['dura']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    voice_feature['uid'] = x.index\n",
    "    voice_feature['voice_mean_dura'] = x.values\n",
    "    \n",
    "    gp = data.groupby('uid')['dura']\n",
    "    x = gp.apply(lambda x: x.max())\n",
    "    voice_feature['uid'] = x.index\n",
    "    voice_feature['voice_max_dura'] = x.values\n",
    "\n",
    "    ## 每个用户每种通话类型的次数\n",
    "    gp = data.groupby(['uid', 'call_type'])['opp_len']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['1','2','3','4','5']\n",
    "    voice_feature['voice_opp_len_type1'] = x['1']\n",
    "    voice_feature['voice_opp_len_type2'] = x['2']\n",
    "    voice_feature['voice_opp_len_type3'] = x['3']\n",
    "    voice_feature['voice_opp_len_type4'] = x['4']\n",
    "    voice_feature['voice_opp_len_type5'] = x['5']\n",
    "    \n",
    "    ## 每个用户每种通话类型的平均时长    \n",
    "    gp = data.groupby(['uid', 'call_type'])['dura']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['1','2','3','4','5']\n",
    "    voice_feature['voice_dura_type1'] = x['1']\n",
    "    voice_feature['voice_dura_type2'] = x['2']\n",
    "    voice_feature['voice_dura_type3'] = x['3']\n",
    "    voice_feature['voice_dura_type4'] = x['4']\n",
    "    voice_feature['voice_dura_type5'] = x['5']\n",
    "\n",
    "    ## 每个用户通话的终端的总数量\n",
    "    gp = data.groupby('uid')['opp_num']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    voice_feature['voice_opp_count_all'] = x.values\n",
    "    \n",
    "    ## 每个用户通话的不同终端的总数量\n",
    "    gp = data.groupby('uid')['opp_num']\n",
    "    x = gp.apply(lambda x: len(set(x)))\n",
    "    voice_feature['voice_opp_count_unique'] = x.values\n",
    "    \n",
    "    ## 每个用户收/发通话的终端的总数量\n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_num']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    voice_feature['voice_opp_count_out'] = x['0']\n",
    "    voice_feature['voice_opp_count_in'] = x['1']\n",
    "    \n",
    "    ## 每个用户收/发通话的终端的不同类型的数量\n",
    "    gp = data.groupby(['uid', 'call_type'])['opp_num']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['1','2','3','4','5']\n",
    "    voice_feature['voice_opp_count_type1'] = x['1']\n",
    "    voice_feature['voice_opp_count_type2'] = x['2']\n",
    "    voice_feature['voice_opp_count_type3'] = x['3']\n",
    "    voice_feature['voice_opp_count_type4'] = x['4']\n",
    "    voice_feature['voice_opp_count_type5'] = x['5']\n",
    "\n",
    "    ## 处理空值\n",
    "    voice_feature.fillna(0,inplace=True)\n",
    "    return voice_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 对用户的短信收发情况统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSmsFeature(data):\n",
    "    sms_feature = pd.DataFrame() \n",
    "    ## 每个用户的短信总数量 丢\n",
    "    gp = data.groupby('uid')['in_out']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    sms_feature['uid'] = x.index\n",
    "    #sms_feature['sms_count'] = x.values\n",
    "    \n",
    "    ## 每个用户收/发短信的总数\n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_len']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    sms_feature['sms_count_out'] = x['0']\n",
    "    sms_feature['sms_count_in'] = x['1']\n",
    "    \n",
    "    ## 每个用户收/发短信的号码的平均长度    \n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_len']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    sms_feature['sms_mean_opp_len_out'] = x['0']\n",
    "    sms_feature['sms_mean_opp_len_in'] = x['1']\n",
    "  \n",
    "    ## 每个用户收发短信的终端的总数量\n",
    "    gp = data.groupby('uid')['opp_num']\n",
    "    x = gp.apply(lambda x: x.count())   \n",
    "    sms_feature['sms_opp_count_all'] = x.values\n",
    "    \n",
    "    ## 每个用户收发短信的不同终端的总数量\n",
    "    gp = data.groupby('uid')['opp_num']\n",
    "    x = gp.apply(lambda x: len(set(x)))\n",
    "    sms_feature['sms_opp_count_unique'] = x.values\n",
    "    \n",
    "    ## 每个用户收/发短信的终端的总数量\n",
    "    gp = data.groupby(['uid', 'in_out'])['opp_num']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    sms_feature['sms_opp_count_out'] = x['0']\n",
    "    sms_feature['sms_opp_count_in'] = x['1']\n",
    "    \n",
    "    ## 处理空值\n",
    "    sms_feature.fillna(0,inplace=True)\n",
    "    return sms_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 对用户的W/A访问情况统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWaFeature(data):\n",
    "    wa_feature = pd.DataFrame()\n",
    "    #每个用户的总访问时长 丢\n",
    "    gp = data.groupby('uid')['visit_dura']\n",
    "    x = gp.apply(lambda x: x.sum())\n",
    "    wa_feature['uid'] = x.index\n",
    "    wa_feature['wa_visit_dura_sum'] = x.values\n",
    "    \n",
    "    ## 每个用户web/APP时长\n",
    "    gp = data.groupby(['uid', 'wa_type'])['visit_dura']\n",
    "    x = gp.apply(lambda x: x.sum())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    wa_feature['web_dura'] = x['0']\n",
    "    wa_feature['APP_dura'] = x['1']\n",
    "    \n",
    "    ## 每个用户web/APP上行流量\n",
    "    gp = data.groupby(['uid', 'wa_type'])['up_flow']\n",
    "    x = gp.apply(lambda x: x.sum())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    wa_feature['web_up_flow'] = x['0']\n",
    "    wa_feature['APP_up_flow'] = x['1']\n",
    "    \n",
    "    ## 每个用户web/APP下行流量\n",
    "    gp = data.groupby(['uid', 'wa_type'])['down_flow']\n",
    "    x = gp.apply(lambda x: x.sum())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    wa_feature['web_down_flow'] = x['0']\n",
    "    wa_feature['APP_down_flow'] = x['1']\n",
    "     \n",
    "    ## 每个用户访问的总数量\n",
    "    gp = data.groupby('uid')['visit_cnt']\n",
    "    x = gp.apply(lambda x: x.sum())\n",
    "    #wa_feature['uid'] = x.index\n",
    "    wa_feature['wa_visit_cnt_sum'] = x.values\n",
    "    \n",
    "    ## 每个用户访问的不同类型的数量\n",
    "    gp = data.groupby('uid')['wa_name']\n",
    "    x = gp.apply(lambda x: len(set(x)))\n",
    "    wa_feature['wa_name_count_unique'] = x.values\n",
    "    \n",
    "    ## 每个用户访问时长的平均\n",
    "    gp = data.groupby('uid')['visit_dura']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    wa_feature['wa_visit_dura_mean'] = x.values\n",
    "    \n",
    "    ## 每个用户上传流量的平均\n",
    "    gp = data.groupby('uid')['up_flow']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    wa_feature['wa_up_flow_mean'] = x.values\n",
    "    \n",
    "    ## 每个用户下载流量的平均\n",
    "    gp = data.groupby('uid')['visit_dura']\n",
    "    x = gp.apply(lambda x: x.mean())\n",
    "    wa_feature['wa_down_flow_mean'] = x.values    \n",
    "    \n",
    "    ## 每个用户访问不同类型的不同地址的数量\n",
    "    gp = data.groupby(['uid', 'wa_type'])['wa_name']\n",
    "    x = gp.apply(lambda x: x.count())\n",
    "    x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "    x.columns=['0','1']\n",
    "    wa_feature['wa_count_type0'] = x['0']\n",
    "    wa_feature['wa_count_type1'] = x['1']\n",
    "    \n",
    "    ## 处理空值\n",
    "    wa_feature.fillna(0,inplace=True)\n",
    "    return wa_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature(voice,sms,wa,uid_label):\n",
    "    #voice = getVoiceFeature(voice_data)\n",
    "    #sms = getSmsFeature(sms_data)\n",
    "    #wa = getWaFeature(wa_data)\n",
    "    fetures = uid_label.merge(voice,how='outer',right_on='uid',left_on='uid')\n",
    "    fetures = fetures.merge(sms,how='outer',right_on='uid',left_on='uid')\n",
    "    fetures = fetures.merge(wa,how='outer',right_on='uid',left_on='uid')\n",
    "    fetures.fillna(0,inplace=True)\n",
    "    return fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = getVoiceFeature(voice_data)\n",
    "sms = getSmsFeature(sms_data)\n",
    "wa = getWaFeature(wa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练and测试\n",
    "uid_label_train, uid_label_test = train_test_split(uid_label)#,test_size=0.2\n",
    "voice_train = voice.loc[voice.uid.isin(uid_label_train['uid'])]\n",
    "voice_test = voice.loc[voice.uid.isin(uid_label_test['uid'])]\n",
    "\n",
    "sms_train = sms.loc[sms.uid.isin(uid_label_train['uid'])]\n",
    "sms_test = sms.loc[sms.uid.isin(uid_label_test['uid'])]\n",
    "\n",
    "wa_train = wa.loc[wa.uid.isin(uid_label_train['uid'])]\n",
    "wa_test = wa.loc[wa.uid.isin(uid_label_test['uid'])]\n",
    "\n",
    "#uid_label_train = uid_label.loc[index_train]\n",
    "#uid_label_test = uid_label.loc[index_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "train = getFeature(voice_train,sms_train,wa_train,uid_label_train)\n",
    "test = getFeature(voice_test,sms_test,wa_test,uid_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>send_voice_cnt</th>\n",
       "      <th>recv_voice_cnt</th>\n",
       "      <th>send_voice_opplen_mean</th>\n",
       "      <th>recv_voice_opplen_mean</th>\n",
       "      <th>voice_mean_dura</th>\n",
       "      <th>voice_max_dura</th>\n",
       "      <th>voice_opp_len_type1</th>\n",
       "      <th>voice_opp_len_type2</th>\n",
       "      <th>...</th>\n",
       "      <th>APP_up_flow</th>\n",
       "      <th>web_down_flow</th>\n",
       "      <th>APP_down_flow</th>\n",
       "      <th>wa_visit_cnt_sum</th>\n",
       "      <th>wa_name_count_unique</th>\n",
       "      <th>wa_visit_dura_mean</th>\n",
       "      <th>wa_up_flow_mean</th>\n",
       "      <th>wa_down_flow_mean</th>\n",
       "      <th>wa_count_type0</th>\n",
       "      <th>wa_count_type1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u3382</td>\n",
       "      <td>0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.007168</td>\n",
       "      <td>305.766852</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>268142494.0</td>\n",
       "      <td>3.529180e+09</td>\n",
       "      <td>6.441790e+09</td>\n",
       "      <td>45368.0</td>\n",
       "      <td>158</td>\n",
       "      <td>56075.225941</td>\n",
       "      <td>151559.405858</td>\n",
       "      <td>56075.225941</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u3533</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.818182</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>510.804878</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12431342.0</td>\n",
       "      <td>8.828077e+08</td>\n",
       "      <td>3.502932e+08</td>\n",
       "      <td>146278.0</td>\n",
       "      <td>322</td>\n",
       "      <td>78528.190700</td>\n",
       "      <td>440910.191126</td>\n",
       "      <td>78528.190700</td>\n",
       "      <td>370.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u4117</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>10.769231</td>\n",
       "      <td>173.543478</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5160684.0</td>\n",
       "      <td>2.099702e+07</td>\n",
       "      <td>4.423116e+07</td>\n",
       "      <td>15271.0</td>\n",
       "      <td>76</td>\n",
       "      <td>57628.501333</td>\n",
       "      <td>252268.472000</td>\n",
       "      <td>57628.501333</td>\n",
       "      <td>117.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u2474</td>\n",
       "      <td>0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>10.960784</td>\n",
       "      <td>11.046083</td>\n",
       "      <td>401.221622</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85998.0</td>\n",
       "      <td>1.175310e+07</td>\n",
       "      <td>1.070810e+05</td>\n",
       "      <td>16302.0</td>\n",
       "      <td>85</td>\n",
       "      <td>33280.854278</td>\n",
       "      <td>51478.164439</td>\n",
       "      <td>33280.854278</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u4353</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>83.258824</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>490601.0</td>\n",
       "      <td>1.534384e+07</td>\n",
       "      <td>3.223930e+05</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11701.642384</td>\n",
       "      <td>48465.291391</td>\n",
       "      <td>11701.642384</td>\n",
       "      <td>184.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid  label  send_voice_cnt  recv_voice_cnt  send_voice_opplen_mean  \\\n",
       "0  u3382      0           703.0           558.0               11.000000   \n",
       "1  u3533      0            33.0             8.0               10.818182   \n",
       "2  u4117      1            20.0            26.0               11.200000   \n",
       "3  u2474      0           153.0           217.0               10.960784   \n",
       "4  u4353      1            64.0           106.0               10.937500   \n",
       "\n",
       "   recv_voice_opplen_mean  voice_mean_dura  voice_max_dura  \\\n",
       "0               11.007168       305.766852          7000.0   \n",
       "1               11.000000       510.804878          5584.0   \n",
       "2               10.769231       173.543478          1225.0   \n",
       "3               11.046083       401.221622          7000.0   \n",
       "4               11.000000        83.258824          4100.0   \n",
       "\n",
       "   voice_opp_len_type1  voice_opp_len_type2       ...        APP_up_flow  \\\n",
       "0               1118.0                 39.0       ...        268142494.0   \n",
       "1                 30.0                  0.0       ...         12431342.0   \n",
       "2                 14.0                 24.0       ...          5160684.0   \n",
       "3                302.0                 12.0       ...            85998.0   \n",
       "4                127.0                  0.0       ...           490601.0   \n",
       "\n",
       "   web_down_flow  APP_down_flow  wa_visit_cnt_sum  wa_name_count_unique  \\\n",
       "0   3.529180e+09   6.441790e+09           45368.0                   158   \n",
       "1   8.828077e+08   3.502932e+08          146278.0                   322   \n",
       "2   2.099702e+07   4.423116e+07           15271.0                    76   \n",
       "3   1.175310e+07   1.070810e+05           16302.0                    85   \n",
       "4   1.534384e+07   3.223930e+05            1328.0                    36   \n",
       "\n",
       "   wa_visit_dura_mean  wa_up_flow_mean  wa_down_flow_mean  wa_count_type0  \\\n",
       "0        56075.225941    151559.405858       56075.225941          1500.0   \n",
       "1        78528.190700    440910.191126       78528.190700           370.0   \n",
       "2        57628.501333    252268.472000       57628.501333           117.0   \n",
       "3        33280.854278     51478.164439       33280.854278            40.0   \n",
       "4        11701.642384     48465.291391       11701.642384           184.0   \n",
       "\n",
       "   wa_count_type1  \n",
       "0           339.0  \n",
       "1            96.0  \n",
       "2            27.0  \n",
       "3             6.0  \n",
       "4            17.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train为训练集的特征，X_test为测试集的特征，y_train是训练集的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['uid','label'],axis=1)\n",
    "X_test = test.drop(['uid','label'],axis=1)\n",
    "y_train = train.label\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    #'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "\n",
    "#准备训练测试集\n",
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train['label'].ravel()\n",
    "x_train = train.drop(['uid','label'], axis=1).values # Creates an array of the train data\n",
    "x_test = test.drop(['uid','label'], axis=1).values # Creats an array of the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止过拟合 划分训练测试集\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "#print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00662153 0.05857787 0.00412793 0.06566667 0.01421012 0.02224972\n",
      " 0.02469939 0.00355617 0.00391679 0.         0.00088134 0.02416222\n",
      " 0.01026464 0.00459763 0.         0.         0.03148262 0.01616451\n",
      " 0.02466251 0.02919745 0.023777   0.00936297 0.00712278 0.\n",
      " 0.         0.00864547 0.01598705 0.0107851  0.15895903 0.00693516\n",
      " 0.04554767 0.03585514 0.02544499 0.01833848 0.03008516 0.01194239\n",
      " 0.03992672 0.01028308 0.04068577 0.00870832 0.01093592 0.00348287\n",
      " 0.02622099 0.02724427 0.03884641 0.02332169 0.01651645]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:305: UserWarning:\n",
      "\n",
      "Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.64601339e-02 4.58638888e-02 2.66704822e-02 6.80818678e-02\n",
      " 1.19929684e-02 1.03360608e-02 3.09411255e-02 1.12856336e-02\n",
      " 5.13962359e-03 1.21901860e-05 5.15422034e-04 3.44562456e-02\n",
      " 1.18412761e-02 5.59150730e-03 1.57932544e-05 4.56699468e-04\n",
      " 2.45853665e-02 1.14801084e-02 1.50567906e-02 4.30742803e-02\n",
      " 3.47325417e-02 1.17604611e-02 5.51490156e-03 1.44541465e-06\n",
      " 6.40959505e-04 4.60682242e-02 2.25228229e-02 9.01446186e-03\n",
      " 9.11177886e-02 1.22249271e-02 4.77575242e-02 4.81717486e-02\n",
      " 2.30973228e-02 3.87714173e-02 1.81667188e-02 1.74085584e-02\n",
      " 1.55774875e-02 9.01305187e-03 1.75840166e-02 1.10209783e-02\n",
      " 3.88225797e-02 2.44646823e-02 2.04965968e-02 1.26373803e-02\n",
      " 2.09267667e-02 1.53323285e-02 1.32948431e-02]\n",
      "[0.03  0.014 0.014 0.048 0.028 0.03  0.008 0.004 0.01  0.    0.    0.002\n",
      " 0.002 0.006 0.    0.    0.016 0.05  0.016 0.01  0.01  0.004 0.006 0.\n",
      " 0.002 0.006 0.024 0.004 0.072 0.02  0.024 0.006 0.028 0.02  0.04  0.046\n",
      " 0.024 0.036 0.054 0.026 0.028 0.038 0.034 0.05  0.026 0.046 0.038]\n",
      "[0.01382166 0.01766288 0.02622205 0.05060681 0.04962913 0.05662395\n",
      " 0.00759172 0.0067441  0.00723553 0.         0.00021175 0.00629148\n",
      " 0.00902773 0.00741712 0.         0.00028868 0.0241176  0.03265946\n",
      " 0.01430115 0.0180209  0.01090831 0.00745174 0.00662584 0.\n",
      " 0.00028838 0.00935221 0.01381853 0.02033058 0.08221512 0.02472029\n",
      " 0.02131022 0.00982768 0.01383425 0.02672157 0.03542719 0.03023474\n",
      " 0.0379614  0.03381288 0.03267449 0.03187523 0.02858939 0.03746587\n",
      " 0.02116252 0.04150615 0.02057528 0.02606056 0.02677591]\n"
     ]
    }
   ],
   "source": [
    "# 得出特征重要性评估\n",
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "ada_feature = ada.feature_importances(x_train, y_train)\n",
    "gb_feature = gb.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二层模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>RandomForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3749.000000</td>\n",
       "      <td>3749.000000</td>\n",
       "      <td>3749.000000</td>\n",
       "      <td>3749.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.148039</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>0.066418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.355186</td>\n",
       "      <td>0.120246</td>\n",
       "      <td>0.338284</td>\n",
       "      <td>0.249044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AdaBoost   ExtraTrees  GradientBoost  RandomForest\n",
       "count  3749.000000  3749.000000    3749.000000   3749.000000\n",
       "mean      0.148039     0.014671       0.131768      0.066418\n",
       "std       0.355186     0.120246       0.338284      0.249044\n",
       "min       0.000000     0.000000       0.000000      0.000000\n",
       "25%       0.000000     0.000000       0.000000      0.000000\n",
       "50%       0.000000     0.000000       0.000000      0.000000\n",
       "75%       0.000000     0.000000       0.000000      0.000000\n",
       "max       1.000000     1.000000       1.000000      1.000000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {\n",
    "    'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": "Viridis",
         "reversescale": true,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest"
         ],
         "y": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest"
         ],
         "z": [
          [
           1,
           0.27397998032753135,
           0.688081607796366,
           0.48603352319809046
          ],
          [
           0.27397998032753135,
           1,
           0.30665757170456576,
           0.42183698876827863
          ],
          [
           0.688081607796366,
           0.30665757170456576,
           1,
           0.5643197500650979
          ],
          [
           0.48603352319809046,
           0.42183698876827863,
           0.5643197500650979,
           1
          ]
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"04c6ddf9-6824-4d92-b6a2-ebe5f3ff0b23\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"04c6ddf9-6824-4d92-b6a2-ebe5f3ff0b23\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.27397998032753135, 0.688081607796366, 0.48603352319809046], [0.27397998032753135, 1.0, 0.30665757170456576, 0.42183698876827863], [0.688081607796366, 0.30665757170456576, 1.0, 0.5643197500650979], [0.48603352319809046, 0.42183698876827863, 0.5643197500650979, 1.0]], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\"], \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\"], \"colorscale\": \"Viridis\", \"showscale\": true, \"reversescale\": true}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"04c6ddf9-6824-4d92-b6a2-ebe5f3ff0b23\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"04c6ddf9-6824-4d92-b6a2-ebe5f3ff0b23\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.27397998032753135, 0.688081607796366, 0.48603352319809046], [0.27397998032753135, 1.0, 0.30665757170456576, 0.42183698876827863], [0.688081607796366, 0.30665757170456576, 1.0, 0.5643197500650979], [0.48603352319809046, 0.42183698876827863, 0.5643197500650979, 1.0]], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\"], \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\"], \"colorscale\": \"Viridis\", \"showscale\": true, \"reversescale\": true}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化第一层模型的相关程度\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= base_predictions_train.astype(float).corr().values ,\n",
    "        x= base_predictions_train.columns.values,\n",
    "        y= base_predictions_train.columns.values,\n",
    "          colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            reversescale = True\n",
    "    )\n",
    "]\n",
    "\n",
    "py.iplot(data, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成第二层模型的训练测试集\n",
    "#x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "#x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)\n",
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning:\n",
      "\n",
      "The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8612934414429815"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二层模型用xgb训练\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1\n",
    "\n",
    ").fit(x_train, y_train)\n",
    "predictions = gbm.predict(x_test)\n",
    "\n",
    "0.4*f1_score(y_test,predictions,average='weighted')+0.6*accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'booster':'gbtree', # 基于树模型\n",
    "    'objective':'multi:softmax',\n",
    "    'stratified':True,\n",
    "    'max_depth':12,\n",
    "    # 'gamma':1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.8,\n",
    "    # 'lambda':1,\n",
    "    'eta':0.5, # 收缩步长\n",
    "    'seed':20,  #\n",
    "    'silent':1,  # 打印运行信息\n",
    "    'num_class':2 #分类数\n",
    "}\n",
    "def evalF1(preds,dtrain):\n",
    "    label = dtrain.get_label()\n",
    "    return 'sco',0.6*accuracy_score(label,preds)+0.4*f1_score(label,preds,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.11403+0.00368871\ttrain-sco:0.883209+0.00329893\ttest-merror:0.117629+0.00737871\ttest-sco:0.879498+0.00740697\n",
      "[10]\ttrain-merror:0.113763+0.00331531\ttrain-sco:0.882895+0.00372241\ttest-merror:0.118162+0.00663143\ttest-sco:0.878455+0.00593107\n",
      "[20]\ttrain-merror:0.11403+0.00343588\ttrain-sco:0.883209+0.003103\ttest-merror:0.117629+0.00737871\ttest-sco:0.879498+0.00740697\n",
      "[30]\ttrain-merror:0.113896+0.00325095\ttrain-sco:0.882768+0.00368494\ttest-merror:0.118162+0.00663143\ttest-sco:0.878455+0.00593107\n",
      "[40]\ttrain-merror:0.113896+0.00325095\ttrain-sco:0.882768+0.00368494\ttest-merror:0.118162+0.00663143\ttest-sco:0.878455+0.00593107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>test-sco-mean</th>\n",
       "      <th>test-sco-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "      <th>train-sco-mean</th>\n",
       "      <th>train-sco-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117629</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.879498</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.11403</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.883209</td>\n",
       "      <td>0.003299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  test-sco-mean  test-sco-std  \\\n",
       "0          0.117629         0.007379       0.879498      0.007407   \n",
       "\n",
       "   train-merror-mean  train-merror-std  train-sco-mean  train-sco-std  \n",
       "0            0.11403          0.003689        0.883209       0.003299  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train,label=y_train)\n",
    "xgb.cv(xgb_params,dtrain,num_boost_round=200,nfold=3,verbose_eval=10,\n",
    "       early_stopping_rounds=50,maximize=True,feval=evalF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.115231\ttrain-sco:0.882524\n",
      "Multiple eval metrics have been passed: 'train-sco' will be used for early stopping.\n",
      "\n",
      "Will train until train-sco hasn't improved in 100 rounds.\n",
      "[10]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "[20]\ttrain-merror:0.115231\ttrain-sco:0.882524\n",
      "[30]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "[40]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "[50]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "[60]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "[70]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "[80]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "[90]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "[100]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "[110]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "[120]\ttrain-merror:0.115231\ttrain-sco:0.880851\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-merror:0.114964\ttrain-sco:0.882778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=xgb.train(xgb_params,dtrain=dtrain,num_boost_round=190,verbose_eval=10,\n",
    "                evals=[(dtrain,'train')],maximize=True,feval=evalF1,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "predictions =model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得出预测结果 保存到文件\n",
    "# Generate Submission File \n",
    "StackingSubmission = pd.DataFrame({ 'uid': test.uid,'label': predictions })\n",
    "StackingSubmission.to_csv(\"./result/baseline_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtest = xgb.DMatrix(X_test)\n",
    "#preds =model.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID_test['label'] =preds\n",
    "#ID_test['label']=ID_test['label']\n",
    "#ID_test.to_csv('./result/baseline_res.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
